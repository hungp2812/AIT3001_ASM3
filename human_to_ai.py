import os
import time
import json
import random
import google.generativeai as genai
from dotenv import load_dotenv

# --- C·∫§U H√åNH ---
INPUT_FILE = "human-write-data.jsonl"  # File d·ªØ li·ªáu g·ªëc c·ªßa b·∫°n
OUTPUT_FILE = "ai-generate-data.jsonl" # File k·∫øt qu·∫£ s·∫Ω l∆∞u v√†o
API_KEY_ENV = "GEMINI_API_KEY"

MODEL_LIST = [
    "models/gemini-2.0-flash-lite",         # ∆Øu ti√™n 1: B·∫£n Lite c·ª±c nhanh
    "models/gemini-2.0-flash",              # ∆Øu ti√™n 2: B·∫£n 2.0 chu·∫©n
    "models/gemini-flash-latest",           # ∆Øu ti√™n 3: Alias chung
    "models/gemini-2.5-flash-lite",         # ∆Øu ti√™n 4: B·∫£n Lite ƒë·ªùi m·ªõi
    "models/gemini-2.0-flash-exp",          # ∆Øu ti√™n 5: B·∫£n th·ª≠ nghi·ªám
    "models/gemini-flash-lite-latest",      # ∆Øu ti√™n 6
    "models/gemini-2.0-pro-exp-02-05",      # D·ª± ph√≤ng cu·ªëi c√πng (Pro ch·∫°y ch·∫≠m h∆°n)
]

load_dotenv()
genai.configure(api_key=os.getenv(API_KEY_ENV))

# Bi·∫øn to√†n c·ª•c theo d√µi v·ªã tr√≠ model ƒëang d√πng
current_model_index = 0

def get_current_model_name():
    return MODEL_LIST[current_model_index]

def switch_model():
    """Chuy·ªÉn sang model k·∫ø ti·∫øp trong danh s√°ch"""
    global current_model_index
    old_model = MODEL_LIST[current_model_index]
    current_model_index = (current_model_index + 1) % len(MODEL_LIST)
    new_model = MODEL_LIST[current_model_index]
    print(f"\n‚ö†Ô∏è Chuy·ªÉn Model: {old_model} -> {new_model}")
    print(f"   (L√Ω do: Model c≈© b·ªã l·ªói ho·∫∑c h·∫øt Quota)\n")

PROMPT_STYLES = [
    "Vi·∫øt l·∫°i ƒëo·∫°n vƒÉn n√†y theo phong c√°ch b√°o ch√≠ kh√°ch quan, d√πng t·ª´ v·ª±ng kh√°c nh∆∞ng gi·ªØ nguy√™n s·ª± ki·ªán.",
    "Paraphrase l·∫°i n·ªôi dung n√†y, thay ƒë·ªïi c·∫•u tr√∫c c√¢u (ch·ªß ƒë·ªông/b·ªã ƒë·ªông) v√† s·ª≠ d·ª•ng t·ª´ ƒë·ªìng nghƒ©a.",
    "T√≥m l∆∞·ª£c v√† vi·∫øt l·∫°i n·ªôi dung sao cho g√£y g·ªçn, s√∫c t√≠ch h∆°n, lo·∫°i b·ªè c√°c t·ª´ d∆∞ th·ª´a.",
    "Thay ƒë·ªïi gi·ªçng vƒÉn ƒë·ªÉ t·∫°o s·ª± t∆∞∆°i m·ªõi nh∆∞ng tuy·ªát ƒë·ªëi gi·ªØ nguy√™n c√°c s·ªë li·ªáu v√† t√™n ri√™ng."
]

def generate_rewritten_text_smart(original_text):
    global current_model_index
    
    # Th·ª≠ t·ªëi ƒëa 5 l·∫ßn (v·ªõi c√°c model kh√°c nhau) cho 1 d√≤ng d·ªØ li·ªáu
    max_retries = 5 
    
    for attempt in range(max_retries):
        model_name = get_current_model_name()
        
        try:
            # Kh·ªüi t·∫°o model
            # L∆∞u √Ω: C√°c model Gemini 2.0/2.5 ƒë·ªÅu h·ªó tr·ª£ t·ªët JSON mode
            model = genai.GenerativeModel(
                model_name,
                generation_config={"response_mime_type": "application/json"}
            )
            
            style = random.choice(PROMPT_STYLES)
            
            prompt = f"""
            B·∫°n l√† m·ªôt tr·ª£ l√Ω AI x·ª≠ l√Ω d·ªØ li·ªáu.
            Nhi·ªám v·ª•: {style}
            
            Y√™u c·∫ßu NGHI√äM NG·∫∂T:
            1. Output ph·∫£i l√† JSON h·ª£p l·ªá: {{ "rewritten_text": "n·ªôi dung..." }}
            2. KH√îNG th√™m b·∫•t k·ª≥ l·ªùi d·∫´n, l·ªùi ch√†o, hay gi·∫£i th√≠ch.
            3. N·∫øu vƒÉn b·∫£n qu√° ng·∫Øn ho·∫∑c v√¥ nghƒ©a, tr·∫£ v·ªÅ chu·ªói r·ªóng.

            VƒÉn b·∫£n g·ªëc:
            "{original_text}"
            """
            
            response = model.generate_content(prompt)
            result = json.loads(response.text)
            return result.get("rewritten_text", None)

        except Exception as e:
            error_msg = str(e)
            
            # X·ª≠ l√Ω c√°c lo·∫°i l·ªói ƒë·ªÉ ƒë·ªïi model
            if "429" in error_msg or "Quota exceeded" in error_msg:
                print(f"‚ùå {model_name} h·∫øt Quota (429).")
                switch_model()
                time.sleep(2) # Ngh·ªâ x√≠u ƒë·ªÉ chuy·ªÉn ƒë·ªïi
                continue
            
            elif "404" in error_msg or "not found" in error_msg:
                print(f"‚ùå {model_name} kh√¥ng t√¨m th·∫•y/l·ªói t√™n.")
                switch_model()
                continue
            
            elif "500" in error_msg or "503" in error_msg: # L·ªói Server Google
                print(f"‚ö†Ô∏è Google Server Error ({model_name}). Th·ª≠ l·∫°i...")
                time.sleep(5)
                continue
                
            else:
                # L·ªói kh√¥ng ph·∫£i do m·∫°ng/quota (v√≠ d·ª• JSON l·ªói) th√¨ b·ªè qua d√≤ng n√†y
                print(f"‚ö†Ô∏è L·ªói x·ª≠ l√Ω ({model_name}): {e}")
                return None
    
    return None

def main():
    # T·∫°o file output n·∫øu ch∆∞a c√≥
    if not os.path.exists(OUTPUT_FILE):
        open(OUTPUT_FILE, 'w', encoding='utf-8').close()

    # ƒê·∫øm s·ªë d√≤ng ƒë√£ l√†m ƒë·ªÉ Resume
    processed_count = 0
    with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
        processed_count = sum(1 for _ in f)

    # ƒê·∫øm t·ªïng s·ªë d√≤ng input
    total_lines = 0
    try:
        with open(INPUT_FILE, 'r', encoding='utf-8') as f:
            total_lines = sum(1 for _ in f)
    except FileNotFoundError:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file {INPUT_FILE}")
        return

    print(f"üöÄ B·∫Øt ƒë·∫ßu! ƒê√£ c√≥ {processed_count} d√≤ng. T·ªïng input: {total_lines}")
    
    with open(INPUT_FILE, 'r', encoding='utf-8') as fin, \
         open(OUTPUT_FILE, 'a', encoding='utf-8') as fout:
        
        for i, line in enumerate(fin):
            # B·ªè qua c√°c d√≤ng ƒë√£ l√†m
            if i < processed_count:
                continue
            
            try:
                data = json.loads(line.strip())
            except:
                continue

            # In ra m√†n h√¨nh tr·∫°ng th√°i
            current_model = get_current_model_name().replace("models/", "")
            print(f"‚è≥ {i+1}/{total_lines} | Model: {current_model}")
            
            original_text = data.get("text", "")
            
            # B·ªè qua text qu√° ng·∫Øn (r√°c)
            if len(original_text) < 30: 
                print("   -> Text qu√° ng·∫Øn, skip.")
                continue

            new_text = generate_rewritten_text_smart(original_text)
            
            if new_text:
                new_record = {
                    "text": new_text,
                    "label": 1, # Label 1 cho AI
                    "meta": data.get("meta", {})
                }
                # C·∫≠p nh·∫≠t meta
                new_record["meta"]["type"] = "ai_generated_rewrite"
                new_record["meta"]["model_used"] = current_model
                
                fout.write(json.dumps(new_record, ensure_ascii=False) + "\n")
                fout.flush() # L∆∞u ngay
            else:
                print("   ‚ö†Ô∏è Failed.")

            # Sleep nh·∫π (3s) ƒë·ªÉ gi·ªØ nh·ªãp, n·∫øu d√πng Lite c√≥ th·ªÉ gi·∫£m xu·ªëng 2s
            time.sleep(3) 

    print("\nüéâ HO√ÄN TH√ÄNH TO√ÄN B·ªò DATASET!")

if __name__ == "__main__":
    main()